<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neural Music Generator</title>
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üéµ</text></svg>">
    <link rel="stylesheet" href="neural-music.css">
</head>
<body>
    <!-- Back Button -->
    <a href="index.html" class="back-button" title="Back to home">üîô</a>
    
    <!-- Info Button -->
    <button class="info-button" id="info-button" title="About this project">‚ÑπÔ∏è</button>
    
    <!-- Info Popup -->
    <div class="info-popup" id="info-popup">
        <div class="info-popup-content">
            <button class="info-popup-close" id="info-popup-close">&times;</button>
            <h2>About</h2>
            <p>This tool was created for CEE 4803 (Art & Generative AI) at the Georgia Institute of Technology.</p>
            <p>It pairs with our Libre textbook, <a href="https://github.com/Fedele-AI/AI_Fundamentals" target="_blank" rel="noopener noreferrer">AI Fundamentals</a>.</p>
            <div class="info-section">
                <h3>Main Developer:</h3>
                <p><a href="https://alexj.io" target="_blank" rel="noopener noreferrer">Kenneth (Alex) Jenkins (TA for CEE 4803)</a></p>
            </div>
            
            <div class="info-section">
                <h3>Overseeing Professor:</h3>
                <p><a href="https://scholar.google.com/citations?user=iaHIkTAAAAAJ" target="_blank" rel="noopener noreferrer">Dr. Francesco Fedele</a></p>
            </div>

            <div class="info-section">
                <h3>Source Code:</h3>
                <p><a href="https://github.com/Fedele-AI/MLvisualizer" target="_blank" rel="noopener noreferrer">ML Visualizer (GPLv3)</a></p>
            </div>
        </div>
    </div>

    <!-- Mobile Warning Popup -->
    <div class="mobile-warning-popup" id="mobile-warning-popup">
        <div class="mobile-warning-content">
            <div class="mobile-warning-icon">?</div>
            <h2>Mobile Warning</h2>
            <p><strong>This feature may still be buggy on mobile devices</strong> due to compute limitations.</p>
            <p>If you experience any issues, please refresh the page.</p>
            <p>Please open an issue on <a href="https://github.com/Fedele-AI/MLvisualizer/issues" target="_blank" rel="noopener noreferrer">GitHub</a>.</p>
            <button class="mobile-warning-close" id="mobile-warning-close">Got it!</button>
        </div>
    </div>

    <!-- No JavaScript Warning (Red X) -->
    <noscript>
        <div class="noscript-warning">
            <div class="noscript-warning-content">
                <div class="noscript-warning-icon"></div>
                <h2>JavaScript Required</h2>
                <p><strong>This site requires JavaScript to function.</strong></p>
                <p>Please enable JavaScript in your browser settings to use this neural music generator.</p>
            </div>
        </div>
    </noscript>

    <!-- WASM Loading Overlay -->
    <div class="wasm-loading-overlay" id="wasm-loading-overlay">
        <div class="wasm-loading-content">
            <div class="wasm-spinner"></div>
            <h2>Initializing Neural Network</h2>
            <p>Loading WebAssembly module...</p>
            <div class="wasm-progress-bar">
                <div class="wasm-progress-fill" id="wasm-progress-fill"></div>
            </div>
        </div>
    </div>

    <div class="container">
        <h1>üéµ Neural Music</h1>
        <p class="subtitle">AI-Generated Music in Your Browser</p>

        <div class="control-group">
            <label>Instrument Sound</label>
            <div class="instrument-selector">
                <button class="instrument-btn active" data-instrument="0">ü§ñ Robo</button>
                <button class="instrument-btn" data-instrument="1">üï∫ 80s</button>
                <button class="instrument-btn" data-instrument="2">üìû Old Nokia</button>
            </div>
        </div>

        <div class="control-group">
            <label for="tempo">Tempo</label>
            <div class="tempo-control">
                <input type="range" id="tempo" min="60" max="240" value="120" step="10">
                <span class="tempo-value"><span id="tempo-display">120</span> BPM</span>
            </div>
            <div class="checkbox-group">
                <input type="checkbox" id="random-spacing-mode" checked>
                <label for="random-spacing-mode">Randomness</label>
                <span class="help-icon" tabindex="0">
                    ?
                    <div class="tooltip">
                        <strong>Random Spacing - Code Implementation</strong><br>
                        Controls whether the transformer inserts random silence (rests) between musical phrases.<br>
                        <strong>üéµ ON (Default):</strong> Adds 1-2 rest notes every 4-8 notes (60% probability), creating natural-sounding phrases with breathing room<br>
                        <strong>üéπ OFF:</strong> Continuous stream of notes with no gaps - one long uninterrupted melody<br>
                        When enabled, rests are inserted as special REST_NOTE values (999) that generate silence in the audio output.
                    </div>
                </span>
            </div>
            <div class="checkbox-group">
                <input type="checkbox" id="melodic-mode">
                <label for="melodic-mode">Melodic</label>
                <span class="help-icon" tabindex="0">
                    ?
                    <div class="tooltip">
                        <strong>Melodic Mode - Code Implementation</strong><br>
                        Controls the transformer's consonance weights applied to interval distances when predicting the next note.<br>
                        <strong>üéπ Harmonic (OFF):</strong> Favors octaves (95%), fourths (95%), unison (100%), thirds (90%)<br>
                        <strong>üéµ Melodic (ON):</strong> Strongly prefers steps 1-2 notes apart (100%), penalizes large leaps (30%), reduces unison to 80% to avoid repetition<br>
                        These weights multiply with attention scores to create the probability distribution for note selection. Higher weight = higher chance of being chosen.
                    </div>
                </span>
            </div>
        </div>

        <div class="control-group">
            <label>Advanced Settings</label>
            <div class="tempo-control">
                <input type="range" id="sample-rate" min="22050" max="48000" step="100" value="44100">
                <span class="tempo-value"><span id="sample-rate-display">44100</span> Hz</span>
            </div>
            <div class="tempo-control" style="margin-top: 12px;">
                <input type="range" id="target-duration" min="5" max="30" step="1" value="12">
                <span class="tempo-value"><span id="target-duration-display">12</span>s</span>
            </div>
        </div>

        <div class="visualizer" id="visualizer">
            <canvas id="neural-canvas"></canvas>
            <div class="visualization-label">Neural Transformer</div>
            <div class="visualization-info" id="viz-info">
                <div class="info-row">
                    <span class="info-label">Layers:</span>
                    <span class="info-value" id="info-layers">4</span>
                </div>
                <div class="info-row">
                    <span class="info-label">Neurons:</span>
                    <span class="info-value" id="info-neurons">56</span>
                </div>
                <div class="info-row">
                    <span class="info-label">Attention:</span>
                    <span class="info-value" id="info-attention">Multi-Head</span>
                </div>
                <div class="info-row">
                    <span class="info-label">Sequence:</span>
                    <span class="info-value" id="info-sequence">0/96</span>
                </div>
                <div class="info-row">
                    <span class="info-label">Active:</span>
                    <span class="info-value" id="info-active">0</span>
                </div>
            </div>
        </div>

        <div class="transformer-stats">
            <div class="stats-title">Transformer Parameters</div>
            <div class="stats-grid">
                <div class="stat-item">
                    <span class="stat-label">Tempo (BPM):</span>
                    <span class="stat-value" id="stat-tempo">120</span>
                </div>
                <div class="stat-item">
                    <span class="stat-label">Instrument:</span>
                    <span class="stat-value" id="stat-instrument">Robo</span>
                </div>
                <div class="stat-item">
                    <span class="stat-label">Mode:</span>
                    <span class="stat-value" id="stat-mode">Harmonic</span>
                </div>
                <div class="stat-item">
                    <span class="stat-label">Sample Rate:</span>
                    <span class="stat-value" id="stat-sample-rate">44100 Hz</span>
                </div>
                <div class="stat-item">
                    <span class="stat-label">Sequence Length:</span>
                    <span class="stat-value" id="stat-seq-length">0</span>
                </div>
                <div class="stat-item">
                    <span class="stat-label">Duration:</span>
                    <span class="stat-value" id="stat-duration">0.0s</span>
                </div>
                <div class="stat-item">
                    <span class="stat-label">Note Duration:</span>
                    <span class="stat-value" id="stat-note-duration">0.0s</span>
                </div>
                <div class="stat-item">
                    <span class="stat-label">Total Samples:</span>
                    <span class="stat-value" id="stat-total-samples">0</span>
                </div>
                <div class="stat-item">
                    <span class="stat-label">Notes (Scale):</span>
                    <span class="stat-value" id="stat-num-notes">8</span>
                </div>
                <div class="stat-item">
                    <span class="stat-label">Target Duration:</span>
                    <span class="stat-value" id="stat-target-duration">12.0s</span>
                </div>
            </div>
        </div>

        <button id="generate-btn">Generate Music</button>
        
        <div class="time-scrubber" id="time-scrubber">
            <div class="waveform-label">Waveform</div>
            <div class="waveform-container">
                <canvas id="waveform-canvas"></canvas>
            </div>
            <div class="scrubber-track" id="scrubber-track">
                <div class="scrubber-progress" id="scrubber-progress"></div>
                <div class="scrubber-handle" id="scrubber-handle"></div>
            </div>
            <div class="player-controls">
                <button class="play-pause-btn" id="play-pause-btn" disabled>
                    <span id="play-pause-icon">‚ñ∂</span>
                </button>
                <div class="time-info">
                    <div class="scrubber-time">
                        <span class="time-display" id="current-time">0:00</span>
                        <span class="time-separator">/</span>
                        <span class="time-display" id="total-time">0:12</span>
                    </div>
                </div>
                <button class="export-btn" id="export-btn">üíæ Download WAV</button>
            </div>
        </div>
        
        <div class="status" id="status">Ready to generate music</div>

        <div class="explanation-section">
            <h2>üß† How Does This Work?</h2>
            
            <div class="diagram">
                <svg viewBox="0 0 800 400" xmlns="http://www.w3.org/2000/svg">
                    <!-- Background -->
                    <rect width="800" height="400" fill="#f7fafc"/>
                    
                    <!-- Title -->
                    <text x="400" y="30" font-size="20" font-weight="bold" text-anchor="middle" fill="#2d3748">Transformer Architecture for Music Generation</text>
                    
                    <!-- Input Layer -->
                    <rect x="50" y="80" width="100" height="260" rx="8" fill="#e6f2ff" stroke="#667eea" stroke-width="2"/>
                    <text x="100" y="125" font-size="14" font-weight="bold" text-anchor="middle" fill="#2d3748">Input</text>
                    <text x="100" y="145" font-size="11" text-anchor="middle" fill="#4a5568">8 Notes</text>
                    <circle cx="100" cy="150" r="6" fill="#667eea"/>
                    <circle cx="100" cy="180" r="6" fill="#667eea"/>
                    <circle cx="100" cy="210" r="6" fill="#667eea"/>
                    <circle cx="100" cy="240" r="6" fill="#667eea"/>
                    <circle cx="100" cy="270" r="6" fill="#667eea"/>
                    <text x="100" y="305" font-size="10" text-anchor="middle" fill="#718096">Previous notes</text>
                    
                    <!-- Attention Layer 1 -->
                    <rect x="230" y="60" width="120" height="280" rx="8" fill="#f0e6ff" stroke="#764ba2" stroke-width="2"/>
                    <text x="290" y="105" font-size="14" font-weight="bold" text-anchor="middle" fill="#2d3748">Attention 1</text>
                    <text x="290" y="125" font-size="11" text-anchor="middle" fill="#4a5568">16 Neurons</text>
                    
                    <!-- Attention connections visualization -->
                    <g opacity="0.6">
                        <line x1="150" y1="150" x2="230" y2="130" stroke="#667eea" stroke-width="1.5"/>
                        <line x1="150" y1="180" x2="230" y2="160" stroke="#667eea" stroke-width="1.5"/>
                        <line x1="150" y1="210" x2="230" y2="190" stroke="#667eea" stroke-width="1.5"/>
                        <line x1="150" y1="240" x2="230" y2="220" stroke="#667eea" stroke-width="1.5"/>
                    </g>
                    
                    <circle cx="290" cy="130" r="7" fill="#8b5cf6"/>
                    <circle cx="290" cy="160" r="7" fill="#8b5cf6"/>
                    <circle cx="290" cy="190" r="7" fill="#8b5cf6"/>
                    <circle cx="290" cy="220" r="7" fill="#8b5cf6"/>
                    <circle cx="290" cy="250" r="7" fill="#8b5cf6"/>
                    <text x="290" y="285" font-size="9" text-anchor="middle" fill="#718096">Weighted</text>
                    <text x="290" y="298" font-size="9" text-anchor="middle" fill="#718096">relationships</text>
                    
                    <!-- Attention Layer 2 -->
                    <rect x="430" y="60" width="120" height="280" rx="8" fill="#f0e6ff" stroke="#764ba2" stroke-width="2"/>
                    <text x="490" y="105" font-size="14" font-weight="bold" text-anchor="middle" fill="#2d3748">Attention 2</text>
                    <text x="490" y="125" font-size="11" text-anchor="middle" fill="#4a5568">16 Neurons</text>
                    
                    <g opacity="0.6">
                        <line x1="350" y1="130" x2="430" y2="140" stroke="#8b5cf6" stroke-width="1.5"/>
                        <line x1="350" y1="160" x2="430" y2="170" stroke="#8b5cf6" stroke-width="1.5"/>
                        <line x1="350" y1="190" x2="430" y2="200" stroke="#8b5cf6" stroke-width="1.5"/>
                        <line x1="350" y1="220" x2="430" y2="230" stroke="#8b5cf6" stroke-width="1.5"/>
                    </g>
                    
                    <circle cx="490" cy="140" r="7" fill="#8b5cf6"/>
                    <circle cx="490" cy="170" r="7" fill="#8b5cf6"/>
                    <circle cx="490" cy="200" r="7" fill="#8b5cf6"/>
                    <circle cx="490" cy="230" r="7" fill="#8b5cf6"/>
                    <circle cx="490" cy="260" r="7" fill="#8b5cf6"/>
                    <text x="490" y="290" font-size="9" text-anchor="middle" fill="#718096">Pattern</text>
                    <text x="490" y="303" font-size="9" text-anchor="middle" fill="#718096">recognition</text>
                    
                    <!-- Output Layer -->
                    <rect x="630" y="80" width="100" height="260" rx="8" fill="#e6fff0" stroke="#48bb78" stroke-width="2"/>
                    <text x="680" y="125" font-size="14" font-weight="bold" text-anchor="middle" fill="#2d3748">Output</text>
                    <text x="680" y="145" font-size="11" text-anchor="middle" fill="#4a5568">8 Notes</text>
                    
                    <g opacity="0.6">
                        <line x1="550" y1="140" x2="630" y2="160" stroke="#8b5cf6" stroke-width="1.5"/>
                        <line x1="550" y1="170" x2="630" y2="190" stroke="#8b5cf6" stroke-width="1.5"/>
                        <line x1="550" y1="200" x2="630" y2="220" stroke="#8b5cf6" stroke-width="1.5"/>
                        <line x1="550" y1="230" x2="630" y2="250" stroke="#8b5cf6" stroke-width="1.5"/>
                    </g>
                    
                    <circle cx="680" cy="160" r="6" fill="#48bb78"/>
                    <circle cx="680" cy="190" r="6" fill="#48bb78"/>
                    <circle cx="680" cy="220" r="6" fill="#48bb78"/>
                    <circle cx="680" cy="250" r="6" fill="#48bb78"/>
                    <circle cx="680" cy="280" r="6" fill="#48bb78"/>
                    <text x="680" y="310" font-size="10" text-anchor="middle" fill="#718096">Next note</text>
                    
                    <!-- Flow arrows -->
                    <defs>
                        <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                            <polygon points="0 0, 10 3.5, 0 7" fill="#667eea"/>
                        </marker>
                    </defs>
                    <line x1="155" y1="360" x2="220" y2="360" stroke="#667eea" stroke-width="2" marker-end="url(#arrowhead)"/>
                    <line x1="360" y1="360" x2="420" y2="360" stroke="#667eea" stroke-width="2" marker-end="url(#arrowhead)"/>
                    <line x1="560" y1="360" x2="620" y2="360" stroke="#667eea" stroke-width="2" marker-end="url(#arrowhead)"/>
                    
                    <text x="187" y="385" font-size="11" text-anchor="middle" fill="#4a5568">Analyze</text>
                    <text x="390" y="385" font-size="11" text-anchor="middle" fill="#4a5568">Learn</text>
                    <text x="590" y="385" font-size="11" text-anchor="middle" fill="#4a5568">Predict</text>
                </svg>
            </div>

            <div class="explanation-text">
                <h3>What is a Transformer?</h3>
                <p>
                    A <strong>transformer</strong> is a type of neural network that's revolutionizing artificial intelligence. 
                    Think of it as a super-smart pattern recognition system that can understand relationships between pieces of information, 
                    no matter how far apart they are in a sequence.
                </p>

                <h3>How Does It Generate Music?</h3>
                <p>Our music transformer works in simple steps:</p>
                <ul>
                    <li><strong>Input Layer:</strong> Takes in the previous musical notes (like C, D, E, etc.)</li>
                    <li><strong>Attention Layers:</strong> The "brain" of the system - it learns which notes sound good together and which patterns create melody. It pays "attention" to the relationships between notes, like how a catchy chorus relates to the verse.</li>
                    <li><strong>Output Layer:</strong> Predicts what the next note should be based on everything it's learned</li>
                </ul>

                <h3>The Same Technology Powers ChatGPT!</h3>
                <p>
                    This exact same architecture powers <strong>ChatGPT</strong> and other large language models! Instead of musical notes, 
                    ChatGPT uses transformers to understand and generate text. The "attention mechanism" helps it understand context - 
                    for example, knowing that "bank" means something different in "river bank" versus "savings bank."
                </p>

                <h3>How Are We Making Music With Code?</h3>
                <p>Here's the magic happening behind the scenes:</p>
                <ul>
                    <li><strong>Rust Code:</strong> The transformer runs in highly efficient Rust code, compiled to WebAssembly (WASM) so it runs at near-native speed in your browser</li>
                    <li><strong>Attention Weights:</strong> Mathematical weights determine how much each previous note influences the next one</li>
                    <li><strong>Probability Distribution:</strong> Instead of random notes, the AI calculates which notes are most "musical" based on consonance (notes that sound good together)</li>
                    <li><strong>Audio Synthesis:</strong> The selected notes are converted into actual sound waves using different waveforms for Piano, Guitar, and Robo sounds</li>
                </ul>

                <h3>The Math Behind Transformers</h3>
                <p>At the heart of every transformer is the <strong>attention mechanism</strong>, which uses these mathematical operations:</p>
                <p style="background: #f7fafc; padding: 20px; border-radius: 8px; font-family: 'Courier New', monospace; overflow-x: auto; margin: 16px 0;">
                    <strong>Attention(Q, K, V)</strong> = softmax(<sup>QK<sup>T</sup></sup>&frasl;<sub>‚àöd<sub>k</sub></sub>) V
                </p>
                <p style="background: #f0e6ff; padding: 20px; border-radius: 8px; font-family: 'Courier New', monospace; overflow-x: auto; margin: 16px 0; line-height: 2;">
                    <strong>Breaking down softmax:</strong><br><br>
                    softmax(z<sub>i</sub>) = <sup>e<sup>z<sub>i</sub></sup></sup>&frasl;<sub>Œ£<sub>j=1</sub><sup>n</sup> e<sup>z<sub>j</sub></sup></sub><br><br>
                    where z = <sup>QK<sup>T</sup></sup>&frasl;<sub>‚àöd<sub>k</sub></sub>
                </p>
                <p><strong>What does this mean in plain English?</strong></p>
                <p>
                    The softmax function is the "decision maker" that turns raw scores into probabilities. Here's how it works:
                </p>
                <ul>
                    <li><strong>e<sup>z<sub>i</sub></sup></strong> (Euler's number to the power of each score) - Amplifies differences between scores. High scores become much higher, low scores stay low.</li>
                    <li><strong>Œ£ (Sigma)</strong> - Sums up all the amplified scores across all positions (j=1 to n)</li>
                    <li><strong>Division</strong> - Each amplified score is divided by the total, guaranteeing all values sum to exactly 1.0 (a perfect probability distribution)</li>
                </ul>
                <p>
                    <strong>Why is this magical?</strong> Imagine you're at a party and trying to decide who to listen to. Softmax is like your brain 
                    calculating: "Person A is pretty interesting (score: 0.5), Person B is fascinating (score: 2.0), Person C is boring (score: -0.3)." 
                    The softmax converts these into percentages: you'll pay 20% attention to A, 70% to B, and 10% to C. 
                </p>
                <p>
                    In music, this means when predicting the next note, the transformer doesn't just pick the "best" note - it creates a probability 
                    distribution across all possible notes. A note that fits the harmony might get 40% probability, a consonant note gets 30%, 
                    and dissonant notes get only 5% each. This creates <strong>musically intelligent randomness</strong> - the AI can explore 
                    creative options while staying mostly in tune!
                </p>
                <p><strong>Key matrices explained:</strong></p>
                <ul>
                    <li><strong>Q</strong> (Query) = "What am I looking for?" (the current musical context)</li>
                    <li><strong>K</strong> (Key) = "What do I have available?" (all previous notes in memory)</li>
                    <li><strong>V</strong> (Value) = "What's the actual musical information?" (the note frequencies and patterns)</li>
                    <li><strong>d<sub>k</sub></strong> = Dimension of the key vectors (prevents numbers from getting too large)</li>
                </ul>
                <p>
                    This formula calculates how much "attention" each note should pay to every other note in the sequence, 
                    creating weighted relationships that capture musical patterns!
                </p>

                <h3>Why Does Everything Sound Piano-Like?</h3>
                <p>
                    You might notice all three instruments (Robo, 80s, Old Nokia) produce similar piano-like tones. This is a 
                    fundamental limitation of running transformers in the browser. Unlike large-scale AI models that can generate 
                    realistic human voices and complex timbres, our browser-based transformer is constrained by:
                </p>
                <ul>
                    <li><strong>Limited computational power:</strong> Full audio synthesis transformers require massive GPU processing</li>
                    <li><strong>Simple waveform generation:</strong> We use basic sine waves with harmonics rather than complex audio modeling</li>
                    <li><strong>Sequence-based prediction:</strong> The transformer predicts note sequences (like MIDI), not raw audio waveforms</li>
                    <li><strong>Browser constraints:</strong> WebAssembly and Web Audio API have performance limits compared to native audio engines</li>
                </ul>
                <p>
                    Think of it this way: our transformer is like a smart musician playing a basic synthesizer, choosing which notes 
                    to play intelligently, but limited to simple electronic sounds. Professional AI music models (like OpenAI's Jukebox 
                    or Google's MusicLM) process millions of audio samples and require powerful servers - far beyond what runs in your browser!
                </p>

                <p>
                    Every time you click "Generate Music," the transformer creates a unique 96-note sequence by repeatedly predicting 
                    the next best note. The result? AI-generated music that sounds pleasant because it's learned the basic rules of harmony 
                    and melody!
                </p>
            </div>
        </div>

        <footer>
            <p>
                <a href="https://github.com/Fedele-AI/MLvisualizer" target="_blank" rel="noopener noreferrer" style="text-decoration: none; color: inherit;">
                    <svg height="16" width="16" viewBox="0 0 16 16" fill="currentColor" style="vertical-align: text-bottom; margin-right: 4px;">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"/>
                    </svg>Neural Music Generator</a> | Built with ‚ù§Ô∏è for CEE 4803 at <a href="https://www.gatech.edu" target="_blank" rel="noopener noreferrer">Georgia Tech</a> | Licensed under <a href="https://www.gnu.org/licenses/gpl-3.0.html" target="_blank" rel="noopener noreferrer">GPLv3</a>
                | <a href="/jslicense.html" rel="jslicense">JavaScript license information</a>
            </p>
        </footer>
    </div>

    <script type="module" src="neural-music.js"></script>
    
    <!-- 100% privacy-first analytics -->
    <script data-collect-dnt="true" async src="https://scripts.simpleanalyticscdn.com/latest.js"></script>
    <noscript><img src="https://queue.simpleanalyticscdn.com/noscript.gif?collect-dnt=true" alt="" referrerpolicy="no-referrer-when-downgrade"/></noscript>
</body>
</html>